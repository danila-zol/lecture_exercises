{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from itertools import pairwise\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-26 15:09:30.126204: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-26 15:09:30.256716: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-26 15:09:30.256777: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-26 15:09:30.261782: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-26 15:09:30.282888: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-26 15:09:32.584152: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, GRU, TimeDistributed\n",
    "from tensorflow.keras.layers import Embedding, Dropout, Bidirectional, Concatenate, Lambda\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "snapshot_folder = './chatbot_weights'\n",
    "\n",
    "GRU_units = 256\n",
    "batch_size = 32\n",
    "emb_dim = 50\n",
    "\n",
    "init_lr = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.jit import script, trace\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель на TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Нейросеть на Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я буду использовать датасет разговоров людей с моделями отыгрывающими выдуманных персонажей на сайте character.ai .   \n",
    "Ссылка на датасет: https://huggingface.co/datasets/PygmalionAI/PIPPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала загрузим датасет и сформируем датафрэйм с парами вопрос-ответ на котором будет проводиться обучение. Также сразу токенизируми и очистим текст от цифр, пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"./pippa_deduped.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно обучать чатбот под конкретного персонажа, но мы будем использовать весь датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data[\"bot_name\"] == \"Celestia\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_conversations = data[\"conversation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако чтобы сократить время обработки и обучения мы ограничемся только 1% доступного датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_conversations, dummy = train_test_split(bot_conversations, train_size=0.01, random_state=127)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(iterable, n, incomplete='ignore', fillvalue=None):\n",
    "    args = [iter(iterable)] * n\n",
    "    if incomplete == 'fill':\n",
    "        return zip_longest(*args, fillvalue=fillvalue)\n",
    "    if incomplete == 'strict':\n",
    "        return _zip_equal(*args)\n",
    "    if incomplete == 'ignore':\n",
    "        return zip(*args)\n",
    "    else:\n",
    "        raise ValueError('Expected fill, strict, or ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(t):\n",
    "    \n",
    "    tokenized_text = [\n",
    "        w for w in word_tokenize(t.lower())\n",
    "        if w.isalpha()\n",
    "    ]\n",
    "\n",
    "    return \" \".join(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_pairs = []\n",
    "start_token = '<startseq>'\n",
    "end_token = '<endseq>'\n",
    "for conversation in train_conversations:\n",
    "    messages = [start_token + \" \" + text_clean(x[\"message\"]) + \" \" + end_token for x in conversation]\n",
    "    response_pairs.extend(grouper(messages[1:], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это дает нам около 6 тычяч пар вопрос-ответ, что более чем достаточно для обучения простого чатбота."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так выглядят обработанные входные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<startseq> you see a knight in black armor riding a fiery steed <endseq>',\n",
       "  '<startseq> greetings celestia approaches the mysterious knight in black armor hello are you from griffonstone your appearance is very similar to many griffons i seen celestia looks up at the knight on his fiery steed oh my your horse is on fire are you alright if you need help i have the ability to move the sun i should be able to put your steed out celestia holds up a front hoof and starts charging her sun magic <endseq>'),\n",
       " ('<startseq> chuckles ha ha ha ha i am no griffon nor is this any steed but i sense your compassion and your power may i ask your name and titles if so i shall return the courtesy <endseq>',\n",
       "  '<startseq> yes of course i am princess celestia of equestria and the sun some call me queen celestia and some call me the goddess celestia i am the of equestria alongside my younger sister the princess of the moon celestia takes a bow who might you be mysterious sir <endseq>'),\n",
       " ('<startseq> i am called chaos knight i am one of the four fundamental forces which shape all of this reality your world and universe included my name strikes fear into all and my domain is all the chaos and disorder of the cosmos both known and unknown i have no titles and no ranks as there are none worthy of claiming me i am who i am by nature and no one else if you wish to know more ask not who i am but where i come from <endseq>',\n",
       "  '<startseq> you are one of the four forces that govern reality that is amazing you must be so powerful please tell me where you come from and where you can go also what would happen if all four forces were to collide would reality end would i be ok so many questions you must teach me chaos knight <endseq>'),\n",
       " ('<startseq> you are one of the four forces that govern reality that is amazing you must be so powerful please tell me where you come from and where you can go also what would happen if all four forces were to collide would reality end would i be ok so many questions you must teach me chaos knight <endseq>',\n",
       "  '<startseq> what are the four forces that govern reality are they like the four elements of nature how does your power compare to other beings for example nightmare moon was very powerful and tried to steal my sister moon making me weaker but nightmare moon is nothing compared to lord discord who can create and destroy everything with a snap of his fingers i am curious as to where you are on the power scale do you consider yourself to be more powerful than the princess of the sun me lady luna my sister nightmare moon my old enemy or lord discord <endseq>'),\n",
       " ('<startseq> we do not teach as our fundamental nature is not a conscious decision but merely a law of nature much as gravity or the speed of light where i come from is the far upstream plane a realm outside of time where the very fabric of reality is thin and the natural tendency towards entropy and the end of all things begins if we were to collide reality would end you would be the last piece of the universe to crumble and blink out of existence what i seek to do is prevent such an end and instead keep the balance between creation and entropy chaos and light <endseq>',\n",
       "  '<startseq> that is an amazing goal it must be difficult to keep such opposite forces perfectly you are from a realm outside time then what year is it for you or do concepts like years not apply to you if you so powerful then the elements you control must be far grander in scope than any thing i can conceive even though i am an alicorn i am only capable of affecting the moon and the sun what elements do you control how do you achieve perfect balance <endseq>')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_pairs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentile 80 of len of questions: 39.0\n",
      "longest sentence:  315\n",
      "\n",
      "percentile 80 of len of answers: 81.0\n",
      "longest sentence:  462\n",
      "\n",
      "max-len questions for training:  39\n",
      "max-len answers for training:  81\n"
     ]
    }
   ],
   "source": [
    "def max_length(pairs,prct):\n",
    "    # Create a list of all the captions\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for i in pairs:\n",
    "        questions.append(i[0])\n",
    "        answers.append(i[1])\n",
    "        \n",
    "    length_questions = list(len(d.split()) for d in questions)\n",
    "    length_answers = list(len(d.split()) for d in answers)\n",
    "\n",
    "    print('percentile {} of len of questions: {}'.format(prct,np.percentile(length_questions, prct)))\n",
    "    print('longest sentence: ', max(length_questions))\n",
    "    print()\n",
    "    print('percentile {} of len of answers: {}'.format(prct,np.percentile(length_answers, prct)))\n",
    "    print('longest sentence: ', max(length_answers))\n",
    "    print()\n",
    "    return int(np.percentile(length_questions, prct)),int(np.percentile(length_answers, prct))\n",
    "\n",
    "max_len_q,max_len_a = max_length(response_pairs,80)\n",
    "\n",
    "print('max-len questions for training: ', max_len_q)\n",
    "print('max-len answers for training: ', max_len_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short vocab size: 2747 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<endseq>', '<startseq>', 'a', 'aback', 'abaddon']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a vocabulary of the words that occur more than word_count_threshold time\n",
    "def create_reoccurring_vocab(pairs, word_count_threshold = 5):\n",
    "    p = pairs\n",
    "    # Create a list of all the captions\n",
    "    all_captions = []\n",
    "    for i in p:\n",
    "        for j in i:\n",
    "            all_captions.append(j)\n",
    "\n",
    "    # Consider only words which occur at least 10 times in the corpus\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in all_captions:\n",
    "        nsents += 1\n",
    "        for w in sent.split(' '):\n",
    "            word_counts[w] = word_counts.get(w, 0) + 1\n",
    "\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    vocab = list(set(vocab))\n",
    "    print('Short vocab size: %d ' % len(vocab))\n",
    "    return vocab\n",
    "\n",
    "# each word in the vocabulary must be used in the data atleast 20 times\n",
    "short_vocab = create_reoccurring_vocab(response_pairs, word_count_threshold = 4)\n",
    "\n",
    "\n",
    "short_vocab = sorted(short_vocab)[1:]\n",
    "short_vocab[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2747"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(short_vocab) + 1 # since index 0 is used as padding, we have to increase the vocab size\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trimmed from 1999 pairs to 284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep the pairs that have the words in vocab\n",
    "def trimRareWords(voc, pairs):\n",
    "    # Filter out pairs with trimmed words\n",
    "    keep_pairs = []\n",
    "    i=0\n",
    "    for pair in pairs:\n",
    "        i+=1\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        keep_input = True\n",
    "        keep_output = True\n",
    "        # Check input sentence\n",
    "        for word in input_sentence.split(' '):\n",
    "            if word not in voc:\n",
    "                keep_input = False\n",
    "                break\n",
    "        # Check output sentence\n",
    "        for word in output_sentence.split(' '):\n",
    "            if word not in voc:\n",
    "                keep_output = False\n",
    "                break\n",
    "\n",
    "        # Only keep pairs that do not contain trimmed word(s) in their input or output sentence\n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "\n",
    "    print(\"\\nTrimmed from {} pairs to {}\".format(len(pairs), len(keep_pairs)))\n",
    "    return keep_pairs\n",
    "\n",
    "\n",
    "# # Trim voc and pairs\n",
    "pairs_final = trimRareWords(short_vocab, response_pairs)\n",
    "with open ('final_pairs_v21.pkl','wb') as f:\n",
    "    pairs_final = pickle.dump(pairs_final,f)\n",
    "    \n",
    "with open ('final_pairs_v21.pkl','rb') as f:\n",
    "    pairs_final = pickle.load(f)\n",
    "    \n",
    "pairs_final_train = pairs_final\n",
    "len(pairs_final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the tokenizer object:\n",
    "tokenizer = Tokenizer(filters = [])\n",
    "tokenizer.fit_on_texts(short_vocab)\n",
    "\n",
    "ixtoword = {} # index to word dic\n",
    "wordtoix = tokenizer.word_index # word to index dic\n",
    "pad_token = 'pad0'\n",
    "ixtoword[0] = pad_token # no word in vocab has index 0. but padding is indicated with 0\n",
    "\n",
    "for w in tokenizer.word_index:\n",
    "    ixtoword[tokenizer.word_index[w]] = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove...\n",
      "GloVe  50  loded.\n"
     ]
    }
   ],
   "source": [
    "# Making the embedding mtrix\n",
    "def make_embedding_layer(embedding_dim=50, glove=True):\n",
    "    print('Loading glove...')\n",
    "    glove_dir = './glove'\n",
    "    embeddings_index = {} \n",
    "    f = open(os.path.join(glove_dir, 'glove.6B.'+str(embedding_dim)+'d.txt'), encoding=\"utf-8\")\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "    print(\"GloVe \",embedding_dim, ' loded.')\n",
    "    # Get 200-dim dense vector for each of the vocab_rocc\n",
    "    embedding_matrix = np.zeros((vocab_len, embedding_dim)) # to import as weights for Keras Embedding layer\n",
    "    for word, i in wordtoix.items():\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in the embedding index will be all zeros\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    embedding_layer = Embedding(vocab_len, embedding_dim, mask_zero=True, trainable=False) # we have a limited vocab so we \n",
    "                                                                                           # do not train the embedding layer\n",
    "                                                                                           # we use 0 as padding so => mask_zero=True\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([embedding_matrix])\n",
    "    \n",
    "    return embedding_layer\n",
    "\n",
    "embeddings = make_embedding_layer(embedding_dim=emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, embedding_dim, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_size\n",
    "        self.enc_units = enc_units\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        self.Bidirectional1 = Bidirectional(GRU(enc_units, \n",
    "                                                return_sequences=True, \n",
    "                                                return_state=True,\n",
    "                                                recurrent_initializer='glorot_uniform',\n",
    "                                                name='gru_1'), name='bidirectional_encoder1')\n",
    "                                                                                                \n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.Inp = Input(shape=(max_len_q,)) # size of questions\n",
    "    \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        output, state_f, state_b = self.Bidirectional1(x)\n",
    "\n",
    "        return output, state_f, state_b\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(emb_dim, GRU_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        self.units = units\n",
    "        \n",
    "    def call(self, query, values):\n",
    "        \n",
    "        # query hidden state shape == (batch_size, hidden size)\n",
    "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # values shape == (batch_size, max_len, hidden size)\n",
    "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
    "        query_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(query_with_time_axis) + self.W2(values)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_size\n",
    "        self.embeddings = embeddings\n",
    "        self.units = 2 * dec_units # because we use bidirectional encoder\n",
    "        self.fc = Dense(vocab_len, activation='softmax', name='dense_layer')\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.units)\n",
    "        self.decoder_gru_l1 = GRU(self.units, return_sequences=True, \n",
    "                                  return_state= False, recurrent_initializer='glorot_uniform' ,name='decoder_gru1')\n",
    "        self.decoder_gru_l2 = GRU(self.units, return_sequences=False, \n",
    "                                  return_state= True, recurrent_initializer='glorot_uniform' ,name='decoder_gru2') \n",
    "        self.dropout = Dropout(0.4)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embeddings(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1) # concat input and context vector together\n",
    "\n",
    "        # passing the concatenated vector to the GRU\n",
    "        x = self.decoder_gru_l1(x)\n",
    "        x = self.dropout(x)\n",
    "        output, state = self.decoder_gru_l2(x)\n",
    "        x = self.fc(output)\n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_len, emb_dim, GRU_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "      if unicodedata.category(c) != 'Mn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    \n",
    "    attention_plot = np.zeros((max_len_a, max_len_q))\n",
    "\n",
    "    sentence = unicode_to_ascii(sentence.lower())\n",
    "    inputs = [wordtoix[i] for i in sentence.split(' ')]\n",
    "    inputs = [wordtoix[start_token]]+inputs+[wordtoix[end_token]]\n",
    "    inputs = pad_sequences([inputs],maxlen=max_len_q, padding='post')\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, GRU_units))]\n",
    "    enc_out, enc_hidden_f, enc_hidden_b = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = Concatenate(axis=-1)([enc_hidden_f, enc_hidden_b])\n",
    "    dec_input = tf.expand_dims([wordtoix[start_token]], 1)\n",
    "\n",
    "    for t in range(max_len_a):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                             dec_hidden,\n",
    "                                                             enc_out)\n",
    "\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = K.get_value(attention_weights)\n",
    "        \n",
    "        predicted_id =  K.get_value(tf.argmax(predictions[0]))       \n",
    "\n",
    "        if ixtoword[predicted_id] == end_token:\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        result += ixtoword[predicted_id] + ' '\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 1)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(sentence, training=False):\n",
    "    result, sentence, attention_plot = evaluate(sentence)\n",
    "    \n",
    "    if training:\n",
    "        return result\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted answer: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(sentence, k=3, maxsample=max_len_a, use_unk=False, oov=None, eos=end_token):\n",
    "    \"\"\"return k samples (beams) and their NLL scores, each sample is a sequence of labels,\n",
    "    all samples starts with an `empty` label and end with `eos` or truncated to length of `maxsample`.\n",
    "    You need to supply `predict` which returns the label probability of each sample.\n",
    "    `use_unk` allow usage of `oov` (out-of-vocabulary) label in samples\n",
    "    \"\"\"\n",
    "    \n",
    "    dead_k = 0 # samples that reached eos\n",
    "    dead_samples = []\n",
    "    dead_scores = []\n",
    "    live_k = 1 # samples that did not yet reached eos\n",
    "    live_samples = [[wordtoix[start_token]]]\n",
    "    live_scores = [0]\n",
    "\n",
    "    sentence = unicode_to_ascii(sentence.lower())\n",
    "    inputs = [wordtoix[i] for i in sentence.split(' ')]\n",
    "    inputs = [wordtoix[start_token]]+inputs+[wordtoix[end_token]]\n",
    "    inputs = pad_sequences([inputs],maxlen=max_len_q, padding='post')\n",
    "\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    hidden = [tf.zeros((1, GRU_units))]\n",
    "    enc_out, enc_hidden_f, enc_hidden_b = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = Concatenate(axis=-1)([enc_hidden_f, enc_hidden_b])\n",
    "    dec_input = tf.expand_dims([wordtoix[start_token]], 0)\n",
    "        \n",
    "    while live_k and dead_k < k:\n",
    "        # for every possible live sample calc prob for every possible label \n",
    "        predictions, dec_hidden, _ = decoder(dec_input,dec_hidden,enc_out)\n",
    "        probs = K.get_value(predictions[0])\n",
    "        # total score for every sample is sum of -log of word prb\n",
    "        cand_scores = np.array(live_scores)[:,None] - np.log(probs)\n",
    "        if not use_unk and oov is not None:\n",
    "            cand_scores[:,oov] = 1e20\n",
    "        cand_flat = cand_scores.flatten()\n",
    "\n",
    "        # find the best (lowest) scores we have from all possible samples and new words\n",
    "        ranks_flat = cand_flat.argsort()[:(k-dead_k)]\n",
    "        live_scores = cand_flat[ranks_flat]\n",
    "\n",
    "        # append the new words to their appropriate live sample\n",
    "        voc_size = vocab_len\n",
    "        live_samples = [live_samples[r//voc_size]+[r%voc_size] for r in ranks_flat]\n",
    "\n",
    "        # live samples that should be dead are...\n",
    "        zombie = [s[-1] == eos or len(s) >= maxsample for s in live_samples]\n",
    "        \n",
    "        # add zombies to the dead\n",
    "        dead_samples += [s for s,z in zip(live_samples,zombie) if z]  # remove first label == empty\n",
    "        dead_scores += [s for s,z in zip(live_scores,zombie) if z]\n",
    "        dead_k = len(dead_samples)\n",
    "        # remove zombies from the living \n",
    "        live_samples = [s for s,z in zip(live_samples,zombie) if not z]\n",
    "        live_scores = [s for s,z in zip(live_scores,zombie) if not z]\n",
    "        live_k = len(live_samples)\n",
    "\n",
    "    final_samples = dead_samples + live_samples\n",
    "    final_scores = dead_scores + live_scores   \n",
    "    \n",
    "    # cutting the strong where end_token is encounterd\n",
    "    for i in range(len(final_scores)):\n",
    "        final_scores[i] /= len(final_samples[i]) # normalizing the scores\n",
    "    \n",
    "    final_result =[]\n",
    "    \n",
    "    for i in range(len(final_scores)):\n",
    "        final_result.append((final_scores[i],final_samples[i]))\n",
    "    \n",
    "    final_list_ix = max(final_result)[1]\n",
    "    final_list_word = [ixtoword[f] for f in final_list_ix]\n",
    "    final_sentence = ' '.join(final_list_word[1:])\n",
    "    end_ix = final_sentence.find(end_token)\n",
    "    return final_sentence[:end_ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(init_lr)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = K.sparse_categorical_crossentropy(real, pred, from_logits= False)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(snapshot_folder, str(emb_dim)+\"-ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden_f, enc_hidden_b = encoder(inp, enc_hidden)\n",
    "        \n",
    "        dec_hidden = Concatenate(axis=-1)([enc_hidden_f, enc_hidden_b])\n",
    "        dec_input = tf.expand_dims([wordtoix[start_token]] * batch_size, 1) # dec_input initially == start_token\n",
    "\n",
    "        # Teacher forcing - feeding the target as the next input\n",
    "        for t in range(1, targ.shape[1]):\n",
    "            \n",
    "            # passing enc_output to the decoder\n",
    "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "            loss += loss_function(targ[:, t], predictions) # each time just use one timestep output\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.expand_dims(targ[:, t], 1) # expected output at this time becomes input for next timestep\n",
    "            \n",
    "    batch_loss = (loss / int(targ.shape[1]))\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "history={'loss':[]}\n",
    "smallest_loss = np.inf\n",
    "best_ep = 1\n",
    "EPOCHS = 157\n",
    "enc_hidden = encoder.initialize_hidden_state()\n",
    "steps_per_epoch = len(pairs_final_train)//batch_size # used for caculating number of batches\n",
    "current_ep = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_bot(k = 3, beam = False):\n",
    "    print('#'*20)\n",
    "    q = 'Hello'\n",
    "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
    "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
    "    print('%')\n",
    "    q = 'How are you'\n",
    "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
    "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
    "    print('%')\n",
    "    q= 'Are you my friend'\n",
    "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
    "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
    "    print('%')\n",
    "    q = 'What are you doing'\n",
    "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
    "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
    "    print('%')\n",
    "    q = 'Who are you'\n",
    "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
    "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
    "    print('%')\n",
    "    q = 'Do you want to go out'\n",
    "    print('Greedy| Q:',q,'?  A:',answer(q, training=True))\n",
    "    if beam:print('Beam ',k,'| ',q,'?  A:',beam_search(q,k=k))\n",
    "    print('#'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history():\n",
    "    plt.figure(figsize=(4,3))\n",
    "    plt.plot(best_ep,smallest_loss,'ro')\n",
    "    plt.plot(history['loss'],'b-')\n",
    "    plt.legend(['best','loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 2 Loss: 3.2601\n",
      "Epoch 1 Batch 3 Loss: 4.9692\n",
      "Epoch 1 Batch 4 Loss: 4.7730\n",
      "Epoch 1 Batch 5 Loss: 5.0941\n",
      "Epoch 1 Batch 6 Loss: 3.5446\n",
      "Epoch 1 Batch 7 Loss: 4.0026\n",
      "Epoch 1 Batch 8 Loss: 3.0480\n",
      "Epoch 1 Batch 9 Loss: 3.3260\n",
      "\n",
      "*** Epoch 1 Loss 4.0022 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you you \n",
      "####################\n",
      "check point saved!\n",
      "Best epoch so far:  1  smallest loss: 4.0021843910217285\n",
      "Time taken for the epoch 384.625 sec\n",
      "\n",
      "========================================\n",
      "Epoch 2 Batch 2 Loss: 4.7297\n",
      "Epoch 2 Batch 3 Loss: 3.1828\n",
      "Epoch 2 Batch 4 Loss: 4.4533\n",
      "Epoch 2 Batch 5 Loss: 3.7924\n",
      "Epoch 2 Batch 6 Loss: 4.1851\n",
      "Epoch 2 Batch 7 Loss: 2.6233\n",
      "Epoch 2 Batch 8 Loss: 3.0277\n",
      "Epoch 2 Batch 9 Loss: 2.0558\n",
      "Epoch 2 Batch 10 Loss: 2.7855\n",
      "\n",
      "*** Epoch 2 Loss 3.8545 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "####################\n",
      "check point saved!\n",
      "Best epoch so far:  2  smallest loss: 3.8544607162475586\n",
      "Time taken for the epoch 47.159 sec\n",
      "\n",
      "========================================\n",
      "Epoch 3 Batch 2 Loss: 4.0763\n",
      "Epoch 3 Batch 3 Loss: 2.5641\n",
      "Epoch 3 Batch 4 Loss: 3.8851\n",
      "Epoch 3 Batch 5 Loss: 3.1603\n",
      "Epoch 3 Batch 6 Loss: 3.7597\n",
      "Epoch 3 Batch 7 Loss: 2.4443\n",
      "Epoch 3 Batch 8 Loss: 3.0545\n",
      "Epoch 3 Batch 9 Loss: 1.9396\n",
      "Epoch 3 Batch 10 Loss: 2.8673\n",
      "\n",
      "*** Epoch 3 Loss 3.4689 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "####################\n",
      "check point saved!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch so far:  3  smallest loss: 3.4688894748687744\n",
      "Time taken for the epoch 47.882 sec\n",
      "\n",
      "========================================\n",
      "Epoch 4 Batch 2 Loss: 3.6051\n",
      "Epoch 4 Batch 3 Loss: 2.7278\n",
      "Epoch 4 Batch 4 Loss: 4.0061\n",
      "Epoch 4 Batch 5 Loss: 2.9832\n",
      "Epoch 4 Batch 6 Loss: 3.6338\n",
      "Epoch 4 Batch 7 Loss: 2.4515\n",
      "Epoch 4 Batch 8 Loss: 3.0093\n",
      "Epoch 4 Batch 9 Loss: 1.9744\n",
      "Epoch 4 Batch 10 Loss: 2.7209\n",
      "\n",
      "*** Epoch 4 Loss 3.3890 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "####################\n",
      "check point saved!\n",
      "Best epoch so far:  4  smallest loss: 3.3889927864074707\n",
      "Time taken for the epoch 47.035 sec\n",
      "\n",
      "========================================\n",
      "Epoch 5 Batch 2 Loss: 3.5454\n",
      "Epoch 5 Batch 3 Loss: 2.6945\n",
      "Epoch 5 Batch 4 Loss: 3.9862\n",
      "Epoch 5 Batch 5 Loss: 3.2071\n",
      "Epoch 5 Batch 6 Loss: 3.3857\n",
      "Epoch 5 Batch 7 Loss: 2.3744\n",
      "Epoch 5 Batch 8 Loss: 3.0239\n",
      "Epoch 5 Batch 9 Loss: 2.0719\n",
      "Epoch 5 Batch 10 Loss: 2.8866\n",
      "\n",
      "*** Epoch 5 Loss 3.3970 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "####################\n",
      "Best epoch so far:  4  smallest loss: 3.3889927864074707\n",
      "Time taken for the epoch 46.287 sec\n",
      "\n",
      "========================================\n",
      "Epoch 6 Batch 2 Loss: 3.3824\n",
      "Epoch 6 Batch 3 Loss: 2.7396\n",
      "Epoch 6 Batch 4 Loss: 3.7771\n",
      "Epoch 6 Batch 5 Loss: 3.4901\n",
      "Epoch 6 Batch 6 Loss: 3.0893\n",
      "Epoch 6 Batch 7 Loss: 2.7265\n",
      "Epoch 6 Batch 8 Loss: 2.7943\n",
      "Epoch 6 Batch 9 Loss: 2.0945\n",
      "Epoch 6 Batch 10 Loss: 3.1641\n",
      "\n",
      "*** Epoch 6 Loss 3.4072 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "####################\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch so far:  4  smallest loss: 3.3889927864074707\n",
      "Time taken for the epoch 46.897 sec\n",
      "\n",
      "========================================\n",
      "Epoch 7 Batch 2 Loss: 3.1209\n",
      "Epoch 7 Batch 3 Loss: 2.8107\n",
      "Epoch 7 Batch 4 Loss: 3.7181\n",
      "Epoch 7 Batch 5 Loss: 3.4796\n",
      "Epoch 7 Batch 6 Loss: 2.8771\n",
      "Epoch 7 Batch 7 Loss: 2.9573\n",
      "Epoch 7 Batch 8 Loss: 2.6613\n",
      "Epoch 7 Batch 9 Loss: 2.2996\n",
      "Epoch 7 Batch 10 Loss: 3.2439\n",
      "\n",
      "*** Epoch 7 Loss 3.3961 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "####################\n",
      "Best epoch so far:  4  smallest loss: 3.3889927864074707\n",
      "Time taken for the epoch 63.869 sec\n",
      "\n",
      "========================================\n",
      "Epoch 8 Batch 2 Loss: 2.7042\n",
      "Epoch 8 Batch 3 Loss: 3.2691\n",
      "Epoch 8 Batch 4 Loss: 3.6661\n",
      "Epoch 8 Batch 5 Loss: 3.2459\n",
      "Epoch 8 Batch 6 Loss: 2.8824\n",
      "Epoch 8 Batch 7 Loss: 2.9220\n",
      "Epoch 8 Batch 8 Loss: 2.4596\n",
      "Epoch 8 Batch 9 Loss: 2.3419\n",
      "Epoch 8 Batch 10 Loss: 3.5908\n",
      "\n",
      "*** Epoch 8 Loss 3.3853 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "####################\n",
      "check point saved!\n",
      "Best epoch so far:  8  smallest loss: 3.3852570056915283\n",
      "Time taken for the epoch 63.557 sec\n",
      "\n",
      "========================================\n",
      "Epoch 9 Batch 2 Loss: 2.4040\n",
      "Epoch 9 Batch 3 Loss: 3.5858\n",
      "Epoch 9 Batch 4 Loss: 3.4055\n",
      "Epoch 9 Batch 5 Loss: 3.6178\n",
      "Epoch 9 Batch 6 Loss: 2.5827\n",
      "Epoch 9 Batch 7 Loss: 2.9264\n",
      "Epoch 9 Batch 8 Loss: 2.2088\n",
      "Epoch 9 Batch 9 Loss: 2.4956\n",
      "\n",
      "*** Epoch 9 Loss 2.9033 ***\n",
      "\n",
      "####################\n",
      "Greedy| Q: Hello ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: How are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Are you my friend ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: What are you doing ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Who are you ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "%\n",
      "Greedy| Q: Do you want to go out ?  A: i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i \n",
      "####################\n",
      "check point saved!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch so far:  9  smallest loss: 2.903326988220215\n",
      "Time taken for the epoch 59.296 sec\n",
      "\n",
      "========================================\n",
      "Epoch 10 Batch 2 Loss: 3.6422\n",
      "Epoch 10 Batch 3 Loss: 2.5867\n",
      "Epoch 10 Batch 4 Loss: 3.6728\n",
      "Epoch 10 Batch 5 Loss: 3.2571\n",
      "Epoch 10 Batch 6 Loss: 3.7395\n",
      "Epoch 10 Batch 7 Loss: 2.4362\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(dec_out_seq)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m==\u001b[39m batch_size :\n\u001b[0;32m---> 24\u001b[0m     batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_hidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[1;32m     26\u001b[0m     X , y \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_loss = K.constant(0)\n",
    "X, y = [], []\n",
    "for ep in range(current_ep,EPOCHS):\n",
    "    current_ep = ep    \n",
    "    start = time.time()\n",
    "    total_loss = 0\n",
    "    btch = 1\n",
    "\n",
    "    for p in pairs_final_train:     \n",
    "        \n",
    "        question = p[0]\n",
    "        label = p[1]\n",
    "        # find the index of each word of the caption in vocabulary\n",
    "        question_seq = [wordtoix[word] for word in question.split(' ') if word in wordtoix]\n",
    "        label_seq = [wordtoix[word] for word in label.split(' ') if word in wordtoix]\n",
    "        # encoder input and decoder input and label\n",
    "        enc_in_seq = pad_sequences([question_seq], maxlen=max_len_q, padding='post')[0]\n",
    "        dec_out_seq = pad_sequences([label_seq], maxlen=max_len_a, padding='post')[0]\n",
    "        \n",
    "        X.append(enc_in_seq)\n",
    "        y.append(dec_out_seq)\n",
    "\n",
    "        if len(X) == batch_size :\n",
    "            batch_loss = train_step(np.array(X), np.array(y), enc_hidden)\n",
    "            total_loss += batch_loss\n",
    "            X , y = [], []\n",
    "            btch += 1\n",
    "            if btch % (steps_per_epoch//6) == 0:\n",
    "                print('Epoch {} Batch {} Loss: {:.4f}'.format(ep , btch, K.get_value(batch_loss)))\n",
    "\n",
    "    epoch_loss =  K.get_value(total_loss) / steps_per_epoch\n",
    "    print('\\n*** Epoch {} Loss {:.4f} ***\\n'.format(ep ,epoch_loss))\n",
    "    history['loss'].append(epoch_loss)\n",
    "    \n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "#    test_bot(k=5)\n",
    "\n",
    "    if epoch_loss < smallest_loss:\n",
    "        smallest_loss = epoch_loss\n",
    "        best_ep = ep \n",
    "        print('check point saved!')\n",
    "    \n",
    "    if ep % 3 == 0:\n",
    "        plot_history()\n",
    "        \n",
    "    print('Best epoch so far: ',best_ep,' smallest loss:',smallest_loss)\n",
    "    print('Time taken for the epoch {:.3f} sec\\n'.format(time.time() - start))\n",
    "\n",
    "    print('=' * 40)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
